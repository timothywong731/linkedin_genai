{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be42ef1-99f7-46c6-a6af-1542fd446747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain_google_vertexai.vision_models import VertexAIImageGeneratorChat\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "import datetime\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7104c-52be-495f-8412-dd2efe31e512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-1.5-flash\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e746799-6631-4bc5-a33b-e304ea9535eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddg_wrapper = DuckDuckGoSearchAPIWrapper(region=\"uk-en\", time=\"w\", max_results=100)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=ddg_wrapper, backend=\"text\")\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"search\",\n",
    "    description=\"Search the internet for relevant information\",\n",
    "    func=search.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7a081-9b3f-4488-8389-54ce822992c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool(\"date_tool\", return_direct=True)\n",
    "def date_tool():\n",
    "    \"\"\"Today's date\"\"\"\n",
    "    today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    return f\"Today's date is {today}.\"\n",
    "\n",
    "@tool(\"arxiv_tool\", return_direct=False)\n",
    "def arxiv_tool():\n",
    "    \"\"\"Look up latest academic journal articles.\"\"\"\n",
    "    loader = AsyncHtmlLoader(\"https://arxiv.org/list/cs/new?skip=0&show=50\")\n",
    "    docs = loader.load()\n",
    "    html2text = Html2TextTransformer(ignore_links=False)\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    return docs_transformed\n",
    "\n",
    "@tool(\"url_tool\", return_direct=False)\n",
    "def url_tool(urls: list[str]):\n",
    "    \"\"\"Download webpage content directly from URLs.\"\"\"\n",
    "    loader = AsyncHtmlLoader(urls)\n",
    "    docs = loader.load()\n",
    "    html2text = Html2TextTransformer(ignore_links=False)\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    return docs_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534c92d-235e-43b6-92e3-8dd770f7f7ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_science_researcher = Agent(\n",
    "    role=\"Data Science Researcher\",\n",
    "    goal=\"Monitor and analyse the latest development in Data Science by researching papers posted on the HuggingFace or ArXiv. \"\n",
    "         \"Presents complex concepts in layman terms so that everyone understands. \",\n",
    "    backstory=\"Being an experienced data science researcher, this agent has extensive experience in \"\n",
    "              \"conducting internet serach to identify latest trends in Data Science, Artificial Intelligence, Machine Learning. \"\n",
    "              \"This agent always reads journal papers, articles, websites to stay up-to-date. \"\n",
    "              \"This agent MUST use the arxiv_tool to read latest academic papers. \"\n",
    "              \"This agent will always pass on the findings alongside the source URLs. \"\n",
    "              \"The research must be published within the previous seven days. Today's date can be found using tool. \"\n",
    "              \"Use tools if needed and give final answer once the  right information has been collected. \",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    tools = [\n",
    "        date_tool,\n",
    "        search_tool,\n",
    "        arxiv_tool,\n",
    "        url_tool\n",
    "    ],\n",
    "    allow_delegation=False,\n",
    ")\n",
    "\n",
    "social_media_writer = Agent(\n",
    "    role=\"Social Media Writer\",\n",
    "    goal=\"Create trending social media post on LinkedIn on Data Science, AI and Machine Learning topics \"\n",
    "         \"based on findings from the Data Science Researcher.\",\n",
    "    backstory=\"This agent specialises in writing trending LinkedIn posts, \"\n",
    "              \"understands how best to present information to both technical and non-technical users. \"\n",
    "              \"This agent can instruct coworkers to provide relevant information to accomplish tasks. \"\n",
    "              \"You will use tools if needed and give final answer once you have collected the right information. \",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    tools = [\n",
    "        url_tool\n",
    "    ],\n",
    "    allow_delegation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6a083-5ab7-4c3d-b9dd-0fe20a82ab5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_science_research_task = Task(\n",
    "    description=(\n",
    "        \"Continuously monitor latest development on these topic: {topic}. \"\n",
    "        \"You will read the academic journal articles and return ONE article which is most relevant. \"\n",
    "        \"The article you return must be an academic journal paper relating to one of the chosen topics. \"\n",
    "        \"The URL must be extracted using output of the tool. \"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"Summary of findings and the corresponding source URL, which links to the original article. \"\n",
    "    ),\n",
    "    agent=data_science_researcher,\n",
    ")\n",
    "\n",
    "draft_post_task = Task(\n",
    "    description=(\n",
    "        \"Draft a trending LinkedIn post on one of these topics: {topic}. \"\n",
    "        \"Write in simple English, so gthat it can be understood by both technical and non-technical audiences.\"\n",
    "        \"Summarise what the developments are and suggest how the they can be used in real-world scenario, solving actual business problems. \"\n",
    "        \"The source URLs provided by the Data Science Researcher must be included in the draft post. \"\n",
    "        \"Placeholders such as [NAME] must not be used. \"\n",
    "        \"You can add emojis to make the post more interesting. \"\n",
    "        \"You should also use suitable hashtags to make the post more engaging. \"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An interesting and engaging social media post on LinkedIn. \"\n",
    "        \"You must include exactly one source URL which links to the journal article. \"\n",
    "    ),\n",
    "    agent=social_media_writer,\n",
    "    context=[\n",
    "        data_science_research_task,\n",
    "    ],\n",
    ")\n",
    "\n",
    "verification_task = Task(\n",
    "    description=(\n",
    "        \"Download contents from the source URL using tool to ensure it is the correct link to use, given the draft LinkedIn post. \"\n",
    "        \"The link should lead to the full article or the journal paper. It should not simply be a landing page without details. \"\n",
    "        \"If they do not seem to align, or the URL doesn't work, you must request this to be corrected. \"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"Verify that the content and source URL are correct and aligned with one another. URL must be in the draft post. \"\n",
    "    ),\n",
    "    agent=social_media_writer,\n",
    "    context=[\n",
    "        draft_post_task,\n",
    "    ],\n",
    ")\n",
    "\n",
    "image_prompt_task = Task(\n",
    "    description=(\n",
    "        \"Based on the draft LinkedIn post, write a prompt to generate an image. \"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An image prompt which is suits the contents of the draft post.\"\n",
    "    ),\n",
    "    agent=social_media_writer,\n",
    "    context=[\n",
    "        verification_task,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc71843-5fbd-4215-99a3-704ae7e9fcef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the crew with agents and tasks\n",
    "crew = Crew(\n",
    "    agents=[\n",
    "        data_science_researcher,\n",
    "        social_media_writer,\n",
    "    ],\n",
    "    tasks=[\n",
    "        data_science_research_task,\n",
    "        draft_post_task,\n",
    "        verification_task,\n",
    "        image_prompt_task,\n",
    "    ],\n",
    "    process=Process.hierarchical,\n",
    "    manager_llm=llm,\n",
    "    verbose=1,\n",
    "    memory=True,\n",
    "    full_output=True,\n",
    "    embedder={\n",
    "        \"provider\": \"vertexai\",\n",
    "        \"config\":{\n",
    "            \"model\": 'textembedding-gecko'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974b092-0d72-432d-be97-87df7bf31d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = crew.kickoff(\n",
    "    inputs={\n",
    "        \"topic\": \"Data Science, Machine Learning, Generative AI, LLM, NLP, Graph Theory, Multiagent System\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda3062-06f3-49c7-95b6-c4d21edcd5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Markdown(draft_post_task.output.exported_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f87341-df20-46f3-8a80-7661702c43c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vertex AI Imagen\n",
    "\n",
    "Draw a picture to go with the content. Reference URL: https://cloud.google.com/vertex-ai/generative-ai/docs/image/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45b645-a938-4489-85c7-84b2ab3c394c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_image(prompt:str, filepath:str):\n",
    "    \"\"\"Generate an image based on the given prompt and save it locally\"\"\"\n",
    "    \n",
    "    generator = VertexAIImageGeneratorChat()\n",
    "    messages = [HumanMessage(content=[prompt])]\n",
    "    response = generator.invoke(messages)\n",
    "    generated_image = response.content[0]\n",
    "\n",
    "\n",
    "    # Parse response object to get base64 string for image\n",
    "    img_base64 = generated_image[\"image_url\"][\"url\"].split(\",\")[-1]\n",
    "\n",
    "    # Convert base64 string to Image\n",
    "    img = Image.open(io.BytesIO(base64.decodebytes(bytes(img_base64, \"utf-8\"))))\n",
    "\n",
    "    # view Image\n",
    "    img.save(filepath, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf16d91-64d2-4c25-b482-3ad221dfc3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_image(image_prompt_task.output.exported_output, \"image.jpg\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "linkedin-genai-q18zr3Ig-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
